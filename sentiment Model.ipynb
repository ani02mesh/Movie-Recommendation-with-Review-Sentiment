{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(['stopwords','punkt_tab'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Def8fAZWuNip",
        "outputId": "5cc230d5-5b1a-43d1-9864-dae2e4ae9c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scipy\n",
        "!pip install --no-cache-dir numpy gensim scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aosEcK-PDmm",
        "outputId": "ccda0c7a-7ece-412a-f968-b9ca72256a7f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scipy 1.14.1\n",
            "Uninstalling scipy-1.14.1:\n",
            "  Successfully uninstalled scipy-1.14.1\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m142.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m193.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m204.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URWRMgsZFBb0",
        "outputId": "84841482-1c62-4628-f1b6-4b3b2a711179",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m481.3/590.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach 1 - Count Vectorizer"
      ],
      "metadata": {
        "id": "jWvK1UuiC44W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "xPe-15gCyLP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_review = pd.read_csv('/content/Reviews.csv')\n",
        "lb = LabelBinarizer()\n",
        "kaggle_review['rating'] = lb.fit_transform(kaggle_review['sentiment'])\n",
        "kaggle_review.drop(columns=['sentiment'],inplace=True)\n",
        "kaggle_review.rename(columns={'review':'Review'},inplace=True)"
      ],
      "metadata": {
        "id": "6VRDIex21DDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopword(text):\n",
        "    return \" \".join([word for word in text.split() if word not in stop_words])"
      ],
      "metadata": {
        "id": "v1jQT6lhyKtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "contractions = {\n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'ll\": \" will\"\n",
        "    }\n",
        "\n",
        "def decontract(text):\n",
        "  decontracted = []\n",
        "  for word in text.split():\n",
        "    if word in contractions:\n",
        "      word = contractions[word]\n",
        "    decontracted.append(word)\n",
        "  return ' '.join(decontracted)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iAgyYFUC0T3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(text):\n",
        "  text = text.lower()             # lower casing\n",
        "  text = re.sub('<.*?>','',text)   #remove HTML Tags\n",
        "  text = emoji.demojize(text)         # remove emojis\n",
        "  text = re.sub('https?://\\S*|www\\.\\S*','',text)   # remove URL's\n",
        "  text = decontract(text)               # decontraction\n",
        "  text = re.sub(r\"'\\w+\", \"\", text)        # remove any letter after '\n",
        "  text = re.sub(r\"\\d+\", \" \", text)        # remove digits [0-9]\n",
        "  text = re.sub(r'\\b\\*\\b', '', re.sub(r'(\\w)\\*(\\w)', r'\\1\\2', text))   # remove * unless its inbetween letters\n",
        "  text = re.sub(r'[^\\x00-\\x7F]+', '', text)     # remove ASCII\n",
        "  text = re.sub(r'[^a-z\\s]', ' ', text)         # remove punctuations\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()      # remove space\n",
        "  return text\n",
        "\n",
        "kaggle_review['Review'] = kaggle_review['Review'].apply(cleaning)\n",
        "kaggle_review['Review'] = kaggle_review['Review'].apply(remove_stopword)"
      ],
      "metadata": {
        "id": "ifKGoDu0yKj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_review_train = kaggle_review[:20000]\n",
        "kaggle_review_test = kaggle_review[30000:40000]"
      ],
      "metadata": {
        "id": "aig18cB7tV7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(kaggle_review_train['Review'],kaggle_review_train['rating'],test_size=0.2,random_state=42)\n",
        "x_train.shape ,x_test.shape ,y_train.shape ,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5BqpHlw4Cws",
        "outputId": "dd70644c-0566-4f5f-f3e1-59a7d6fcb9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16000,), (4000,), (16000,), (4000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "x_train_bow = cv.fit_transform(x_train).toarray()\n",
        "x_test_bow = cv.transform(x_test).toarray()\n",
        "\n",
        "x_train_bow.shape , x_test_bow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "munXJR5iyKhL",
        "outputId": "1b92dece-3447-47fe-8fca-cbd8eac021d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16000, 63298), (4000, 63298))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(x_train_bow,y_train)\n",
        "y_pred = rfc.predict(x_test_bow)\n",
        "print('accuray - ',accuracy_score(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuNb3whe72D9",
        "outputId": "e45c4047-8481-4dd7-82b0-cd0d9b93865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuray -  0.84975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = cv.transform(kaggle_review_test['Review']).toarray()\n",
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVqmrW0Zv8nT",
        "outputId": "215d0c86-1ce1-4915-c15a-c5125beaf3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 63298)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rfc.predict(test)\n",
        "y_testt = kaggle_review_test['rating']\n",
        "print('accuray - ',accuracy_score(y_testt,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjHJFtUXvazn",
        "outputId": "247cb0a0-44ac-4bb7-c01a-3408f9af37d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuray -  0.8434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_review = pd.read_csv('/content/F_review.csv')[['rating','summary','review']]\n",
        "scrape_review['Review'] = scrape_review['summary'] +\" \"+ scrape_review['review']\n",
        "scrape_review.drop(columns=['summary','review'],inplace=True)"
      ],
      "metadata": {
        "id": "cvtOWPrKNyty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_review = scrape_review.sample(10000,random_state=4)\n",
        "test_review['Review'] = test_review['Review'].apply(cleaning)\n",
        "test_review['Review'] = test_review['Review'].apply(remove_stopword)\n",
        "\n",
        "testing_rev = cv.transform(test_review['Review']).toarray()"
      ],
      "metadata": {
        "id": "5K0Gjv8ZOw1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rfc.predict(testing_rev)\n",
        "y_testt = test_review['rating']\n",
        "print('accuray - ',accuracy_score(y_testt,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ekBp_dbQObH",
        "outputId": "173977db-b6cd-44df-9a83-aecc5e7a8209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuray -  0.8861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Overall the experience was so crap. but in some portion the movie was bad'\n",
        "\n",
        "def sentiment(text):\n",
        "  text = cleaning(text)\n",
        "  text = remove_stopword(text)\n",
        "  input = cv.transform([text]).toarray()\n",
        "  pred = rfc.predict(input)\n",
        "  prediction = 'positive' if pred[0]==1 else 'negative'\n",
        "  return prediction\n",
        "\n",
        "sentiment(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bxakW7xyyKdB",
        "outputId": "1c419d61-b0db-477c-ebcf-f20dc7af95e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach 2 - keras tokenizer and keras embedding"
      ],
      "metadata": {
        "id": "gUMqOjU9WGWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Input, Dropout, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "OiLZ3-KsWFVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_review = pd.read_csv('/content/Reviews.csv')\n",
        "kaggle_review.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mug80XoSWFSQ",
        "outputId": "91c52e94-6dbf-4c97-ab4b-be9fc0b9ad2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "kaggle_review['rating'] = lb.fit_transform(kaggle_review['sentiment'])\n",
        "kaggle_review.drop(columns=['sentiment'],inplace=True)\n",
        "kaggle_review.rename(columns={'review':'Review'},inplace=True)"
      ],
      "metadata": {
        "id": "QzwTk1HmWFOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "contractions = {\n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'ll\": \" will\"\n",
        "    }\n",
        "\n",
        "def decontract(text):\n",
        "  decontracted = []\n",
        "  for word in text.split():\n",
        "    if word in contractions:\n",
        "      word = contractions[word]\n",
        "    decontracted.append(word)\n",
        "  return ' '.join(decontracted)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8Br8EwWTWFKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(text):\n",
        "  text = text.lower()             # lower casing\n",
        "  text = re.sub('<.*?>','',text)   #remove HTML Tags\n",
        "  text = emoji.demojize(text)         # remove emojis\n",
        "  text = re.sub('https?://\\S*|www\\.\\S*','',text)   # remove URL's\n",
        "  text = decontract(text)               # decontraction\n",
        "  text = re.sub(r\"'\\w+\", \"\", text)        # remove any letter after '\n",
        "  text = re.sub(r\"\\d+\", \" \", text)        # remove digits [0-9]\n",
        "  text = re.sub(r'\\b\\*\\b', '', re.sub(r'(\\w)\\*(\\w)', r'\\1\\2', text))   # remove * unless its inbetween letters\n",
        "  text = re.sub(r'[^\\x00-\\x7F]+', '', text)     # remove ASCII\n",
        "  text = re.sub(r'[^a-z\\s]', ' ', text)         # remove punctuations\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()      # remove space\n",
        "  return text\n",
        "\n",
        "kaggle_review['Review'] = kaggle_review['Review'].apply(cleaning)"
      ],
      "metadata": {
        "id": "Ej2aDU6OWFG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data = train_test_split(kaggle_review,test_size=0.2,random_state=41)\n",
        "train_data.shape ,test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Umxj2KFWFMQ",
        "outputId": "34e2e823-c413-4ca8-c9f9-a7571d7f2cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 2), (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews = train_data['Review'].astype(str).tolist()\n",
        "test_reviews = test_data['Review'].astype(str).tolist()\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_reviews)"
      ],
      "metadata": {
        "id": "R3p7omEjWFEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = pad_sequences(tokenizer.texts_to_sequences(train_reviews),maxlen=200)\n",
        "test_sequences = pad_sequences(tokenizer.texts_to_sequences(test_reviews),maxlen=200)"
      ],
      "metadata": {
        "id": "3ty7NUC9yQLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data['rating']\n",
        "y_test = test_data['rating']\n",
        "\n",
        "train_sequences.shape,test_sequences.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "6PCM52rVy2Sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de31a5f-f505-4b97-b59c-cfdb741aefdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 200), (10000, 200), (40000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=5000,output_dim=100))\n",
        "# model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.3,return_sequences=False))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=5000, output_dim=100, input_length=200))\n",
        "# model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.3))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(200,))  # ✅ No batch shape, just the input shape\n",
        "x = Embedding(input_dim=5000, output_dim=100)(input_layer)\n",
        "x = LSTM(128, dropout=0.2, recurrent_dropout=0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)"
      ],
      "metadata": {
        "id": "BWk1-6jwmNxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "pUuceVA53V4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_sequences,y_train,epochs=8,validation_split=0.2,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlvW8b15WFAd",
        "outputId": "969c72f7-d807-4417-bfd5-29d1b8039fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 387ms/step - accuracy: 0.7413 - loss: 0.5036 - val_accuracy: 0.8754 - val_loss: 0.3091\n",
            "Epoch 2/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 381ms/step - accuracy: 0.8825 - loss: 0.2924 - val_accuracy: 0.8808 - val_loss: 0.2922\n",
            "Epoch 3/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 379ms/step - accuracy: 0.9004 - loss: 0.2529 - val_accuracy: 0.8786 - val_loss: 0.2955\n",
            "Epoch 4/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 375ms/step - accuracy: 0.8993 - loss: 0.2550 - val_accuracy: 0.8790 - val_loss: 0.2998\n",
            "Epoch 5/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 377ms/step - accuracy: 0.9256 - loss: 0.1960 - val_accuracy: 0.8780 - val_loss: 0.3171\n",
            "Epoch 6/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 377ms/step - accuracy: 0.9317 - loss: 0.1811 - val_accuracy: 0.8764 - val_loss: 0.3179\n",
            "Epoch 7/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 378ms/step - accuracy: 0.9433 - loss: 0.1495 - val_accuracy: 0.8679 - val_loss: 0.3448\n",
            "Epoch 8/8\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 377ms/step - accuracy: 0.9525 - loss: 0.1325 - val_accuracy: 0.8734 - val_loss: 0.3953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc412460e50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_sequences,y_test)"
      ],
      "metadata": {
        "id": "AjszM8ZkjJ3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac00d26b-86a2-48b3-9ef0-d5255f4bceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.8676 - loss: 0.4020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40222087502479553, 0.8687999844551086]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_rev = pad_sequences(tokenizer.texts_to_sequences(test_review['Review']),maxlen=200)\n",
        "model.evaluate(test_rev,test_review['rating'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3eNGzomZ28s",
        "outputId": "bba07a86-ad78-4b3c-e7dc-e0f02be64635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 115ms/step - accuracy: 0.8924 - loss: 0.3082\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3006880581378937, 0.895799994468689]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'this is cinema. such movie make me fall in love with cinema all over again. what a msterpiece it is. from acting to background score, everything is perfect.'\n",
        "\n",
        "def sentiment(text):\n",
        "  text = cleaning(text)\n",
        "  input = pad_sequences(tokenizer.texts_to_sequences([text]),maxlen=200)\n",
        "  pred = model.predict(input)\n",
        "  prediction = 'positive' if pred[0][0]>0.5 else 'negative'\n",
        "  return prediction\n",
        "\n",
        "sentiment(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RWutVuNLjJz7",
        "outputId": "c41e0450-2d6a-4a67-8739-087bfce46d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('review_sentiment3.keras')             # this is the model we using <------"
      ],
      "metadata": {
        "id": "ZAVe9vkrc43e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "75IgWY58dqHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach 3 - Word Embedding using Word2Vec"
      ],
      "metadata": {
        "id": "_IPNaPTiGnt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import gensim\n",
        "from gensim.models import word2vec,KeyedVectors\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "vZmfT_ZKjJxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_review = pd.read_csv('/content/Reviews.csv')\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "kaggle_review['rating'] = lb.fit_transform(kaggle_review['sentiment'])\n",
        "kaggle_review.drop(columns=['sentiment'],inplace=True)\n",
        "kaggle_review.rename(columns={'review':'Review'},inplace=True)"
      ],
      "metadata": {
        "id": "1rnW12jyIPpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_texts = kaggle_review['Review'].tolist()\n",
        "reviews = [text.split() for text in review_texts]"
      ],
      "metadata": {
        "id": "EN7MZQK7jJui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(window=10,min_count=2,vector_size=50)\n",
        "model.build_vocab(reviews)"
      ],
      "metadata": {
        "id": "25ygj2xljJrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(kaggle_review['Review'],total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "id": "_Wi9ifSVjJo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4969c72-7761-4d73-ed0c-171152376e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95896935, 203331885)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv.index_to_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfjnqmC0BfU8",
        "outputId": "ab02d868-6483-4d1c-b44e-ebdb8b53efbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_token = []\n",
        "word_to_index = {word: idx+1 for idx, word in enumerate(model.wv.index_to_key)}\n",
        "\n",
        "embedding_matrix = np.zeros((62072, 50))\n",
        "\n",
        "for word, idx in word_to_index.items():\n",
        "    if word in model.wv:\n",
        "        embedding_matrix[idx] = model.wv[word]"
      ],
      "metadata": {
        "id": "n3EEnbimKE6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rev in kaggle_review['Review']:\n",
        "  review_token.append([word_to_index[word] for word in rev.split() if word in word_to_index])"
      ],
      "metadata": {
        "id": "ZsMnUNen-Nr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revise = pad_sequences(review_token,maxlen=200)"
      ],
      "metadata": {
        "id": "TtN3UpjbTNTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = kaggle_review['rating'].values"
      ],
      "metadata": {
        "id": "l-0uho4_TM8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(revise,Y,test_size=0.2,random_state=41)\n",
        "x_train.shape ,x_test.shape ,y_train.shape ,y_test.shape"
      ],
      "metadata": {
        "id": "jgQoreQYTM5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f2f88a-e3e3-4980-e340-f9f30654459d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 200), (10000, 200), (40000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_embedded = np.array([[embedding_matrix[idx] for idx in review] for review in x_train])"
      ],
      "metadata": {
        "id": "56Plje_5TM2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_embedded = np.array([[embedding_matrix[idx] for idx in review] for review in x_test])"
      ],
      "metadata": {
        "id": "w3x2t-Eo2_FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_embedded.shape ,x_test_embedded.shape ,y_train.shape ,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNMWtO6X2_Co",
        "outputId": "589ef25c-eba9-462a-e11f-bd7402b70c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 200, 50), (10000, 200, 50), (40000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(200, 50)))\n",
        "model.add(LSTM(256,dropout=0.2,recurrent_dropout=0.3,return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# model = Sequential([\n",
        "#     Input(shape=(200, 50)),\n",
        "#     Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.3)),  # First BiLSTM\n",
        "#     BatchNormalization(),  # Normalize activations\n",
        "#     Dense(64, activation='relu'),  # Fully connected layer\n",
        "#     Dropout(0.4),  # Reduce overfitting\n",
        "#     Dense(1, activation='sigmoid')  # Output for binary classification\n",
        "# ])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0yxB3RlN2-_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "a01ea012-a665-4819-8bde-03ef81358639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m314,368\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">314,368</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m314,625\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,625</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m314,625\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,625</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "VyRkxjeVNlvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_embedded,y_train,epochs=5,validation_data=[x_test_embedded,y_test],batch_size=64)"
      ],
      "metadata": {
        "id": "CJbDbfbyNlsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}